{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook creates and trains a FCN model which deals with count-based encoded data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Possible critical alarm types\n",
    "critical_alarm_types = [7,15,16,21,33,56,68,95,1000,1001]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in critical_alarm_types:\n",
    "    # Replace the link according to the data you want to read (All, Unique Samples, Random Samples)\n",
    "    type_df = pd.read_csv(\"../Data/Final Data/Train/Random Samples/Count-based/\" + str(i) + \"_countbased.csv\")\n",
    "    df = pd.concat([df, type_df], ignore_index=True)\n",
    "\n",
    "X = df.drop(columns=['y']).values\n",
    "y = df['y'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T23:29:46.131269Z",
     "end_time": "2023-11-24T23:29:59.026542Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you wish to perform an upsampling using SMOTE, run the following cell. If you do not wish to perform an upsampling, bypass the following cell and run the next one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Upsampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X, y = sm.fit_resample(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1-hot-encoding of the labels and train-test-split\n",
    "\n",
    "# Determine the number of unique critical error types\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Encode the target variable using LabelEncoder and one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating the architecture of the FCN\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense, BatchNormalization, Dropout\n",
    "\n",
    "def create_model(filters, kernel_size):\n",
    "    # Create the FCN model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding='same', input_shape=(77, 1)))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters*2, kernel_size, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters*2, kernel_size, activation='relu', padding='same'))\n",
    "\n",
    "    # Decoder\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding='same'))\n",
    "\n",
    "    # Global average pooling\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # Dense layer for classification\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Print the model summary\n",
    "\n",
    "model = create_model(64,9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                        mode=\"min\", patience=3,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_test, y_test), callbacks=[earlystopping])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'FCN_countbased.joblib')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prediction with test data\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Undo 1-hot-encoding of the class labels\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_pred_classes = []\n",
    "y_real_classes = []\n",
    "\n",
    "# Undo 1-hot-encoding of labels\n",
    "for item in y_pred:\n",
    "    y_pred_classes.append(np.argmax(item))\n",
    "\n",
    "for item in y_test:\n",
    "    y_real_classes.append(np.argmax(item))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Classification report for train-test-split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['7', '15', '16', '21', '33', '56', '68', '95', '1000', '1001']\n",
    "print(classification_report(y_real_classes, y_pred_classes, target_names=label_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_names = ['7', '15', '16', '21', '33', '56', '68', '95', '1000', '1001']\n",
    "\n",
    "cm = confusion_matrix(y_real_classes, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
    "disp.plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
