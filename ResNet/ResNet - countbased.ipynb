{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook creates and trains a ResNet model that deals with count-based encoded data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Possible critical alarm types\n",
    "critical_alarm_types = [7,15,16,21,33,56,68,95,1000,1001]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in critical_alarm_types:\n",
    "    # Replace the link according to the data you want to read (All, Unique Samples, Random Samples)\n",
    "    type_df = pd.read_csv(\"../Data/Final Data/Train/Random Samples/Count-based/\" + str(i) + \"_countbased.csv\")\n",
    "    df = pd.concat([df, type_df], ignore_index=True)\n",
    "\n",
    "X = df.drop(columns=['y']).values\n",
    "y = df['y'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T23:29:08.937050Z",
     "end_time": "2023-11-24T23:29:24.710899Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you wish to perform an upsampling using SMOTE, run the following cell. If you do not wish to perform an upsampling, bypass the following cell and run the next one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Upsampling using SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X, y = sm.fit_resample(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1-hot-encoding of the class labels and train-test-split\n",
    "\n",
    "# Determine the number of unique critical error types\n",
    "num_classes = len(np.unique(y))\n",
    "print(num_classes)\n",
    "\n",
    "# Encode the target variable using LabelEncoder and one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating the ResNet architecture\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Add, GlobalAveragePooling1D, Dense\n",
    "\n",
    "def residual_block(input_tensor, filters, kernel_size, strides=1):\n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Downsample the input tensor if strides=2\n",
    "    if strides == 2:\n",
    "        input_tensor = Conv1D(filters, 1, strides=strides, padding='same')(input_tensor)\n",
    "\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=(77, 1))\n",
    "\n",
    "# Initial convolution\n",
    "x = Conv1D(64, 7, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Residual blocks\n",
    "x = residual_block(x, 64, 9)\n",
    "x = residual_block(x, 64, 9)\n",
    "x = residual_block(x, 64, 9)\n",
    "\n",
    "x = residual_block(x, 128, 9, strides=2)\n",
    "x = residual_block(x, 128, 9)\n",
    "x = residual_block(x, 128, 9)\n",
    "\n",
    "x = residual_block(x, 256, 9, strides=2)\n",
    "x = residual_block(x, 256, 9)\n",
    "x = residual_block(x, 256, 9)\n",
    "\n",
    "# Global average pooling\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                        mode=\"min\", patience=3,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[earlystopping])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['ResNet_sequences_all_smote.joblib']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'ResNet_sequences_all_smote.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-18T19:23:18.532122Z",
     "end_time": "2023-11-18T19:23:19.308121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prediction with test data\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Undo 1-hot-encoding of the class labels\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_pred_classes = []\n",
    "y_real_classes = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_classes.append(np.argmax(item))\n",
    "\n",
    "for item in y_test:\n",
    "    y_real_classes.append(np.argmax(item))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "#\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['7', '15', '16', '21', '33', '56', '68', '95', '1000', '1001']\n",
    "print(classification_report(y_real_classes, y_pred_classes, target_names=label_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_names = ['7', '15', '16', '21', '33', '56', '68', '95', '1000', '1001']\n",
    "\n",
    "cm = confusion_matrix(y_real_classes, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
    "disp.plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
