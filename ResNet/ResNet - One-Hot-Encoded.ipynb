{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "959fd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import csv\n",
    "\n",
    "# Read data for X and y\n",
    "X = pd.read_csv(\"data/X.csv\").values\n",
    "y = pd.read_csv(\"data/y.csv\").values\n",
    "\n",
    "# Flatten list y\n",
    "y = [item for sublist in y for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2992537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "#sm = SMOTE(random_state=42)\n",
    "#X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = oversampler.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "773c018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique critical error types\n",
    "num_classes = len(np.unique(y_res))\n",
    "class_names = np.unique(y_res)\n",
    "\n",
    "# Encode the target variable using LabelEncoder and one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_res = label_encoder.fit_transform(y_res)\n",
    "y_res = to_categorical(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b8465ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding for sequences in X\n",
    "import numpy as np\n",
    "\n",
    "list_of_sequences = X_res\n",
    "\n",
    "# Create a set of unique IDs\n",
    "unique_ids = set()\n",
    "for sequence in list_of_sequences:\n",
    "    unique_ids.update(sequence)\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "sorted_unique_ids = sorted(unique_ids)\n",
    "\n",
    "# Create a dictionary mapping each ID to its index\n",
    "id_to_index = {id: index for index, id in enumerate(sorted_unique_ids)}\n",
    "\n",
    "# One-hot encode each sequence separately\n",
    "encoded_sequences = []\n",
    "for sequence in list_of_sequences:\n",
    "    encoded_sequence = np.zeros((len(sequence), len(sorted_unique_ids)), dtype=int)\n",
    "    for i, id in enumerate(sequence):\n",
    "        index = id_to_index[id]\n",
    "        encoded_sequence[i, index] = 1\n",
    "    encoded_sequences.append(encoded_sequence)\n",
    "\n",
    "X_res = encoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5aa40b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "624f2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 300, 64)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 300, 64)      28736       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 300, 64)     256         ['conv1d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 300, 64)      0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 300, 64)      12352       ['activation_76[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 300, 64)     256         ['conv1d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 300, 64)      0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 300, 64)      12352       ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 300, 64)     256         ['conv1d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 300, 64)      0           ['batch_normalization_78[0][0]', \n",
      "                                                                  'activation_76[0][0]']          \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 300, 64)      0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 300, 64)      12352       ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 300, 64)     256         ['conv1d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 300, 64)      0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 300, 64)      12352       ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 300, 64)     256         ['conv1d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 300, 64)      0           ['batch_normalization_80[0][0]', \n",
      "                                                                  'activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 300, 64)      0           ['add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 300, 64)      12352       ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 300, 64)     256         ['conv1d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 300, 64)      0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 300, 64)      12352       ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 300, 64)     256         ['conv1d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 300, 64)      0           ['batch_normalization_82[0][0]', \n",
      "                                                                  'activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 300, 64)      0           ['add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 150, 128)     24704       ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 150, 128)    512         ['conv1d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 150, 128)     0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_92 (Conv1D)             (None, 150, 128)     49280       ['activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 150, 128)    512         ['conv1d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_93 (Conv1D)             (None, 150, 128)     8320        ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 150, 128)     0           ['batch_normalization_84[0][0]', \n",
      "                                                                  'conv1d_93[0][0]']              \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 150, 128)     0           ['add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_94 (Conv1D)             (None, 150, 128)     49280       ['activation_84[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 150, 128)    512         ['conv1d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 150, 128)     0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_95 (Conv1D)             (None, 150, 128)     49280       ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 150, 128)    512         ['conv1d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 150, 128)     0           ['batch_normalization_86[0][0]', \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 150, 128)     0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_96 (Conv1D)             (None, 150, 128)     49280       ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 150, 128)    512         ['conv1d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 150, 128)     0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_97 (Conv1D)             (None, 150, 128)     49280       ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 150, 128)    512         ['conv1d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 150, 128)     0           ['batch_normalization_88[0][0]', \n",
      "                                                                  'activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 150, 128)     0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_98 (Conv1D)             (None, 75, 256)      98560       ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 75, 256)     1024        ['conv1d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 75, 256)      0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_99 (Conv1D)             (None, 75, 256)      196864      ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 75, 256)     1024        ['conv1d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_100 (Conv1D)            (None, 75, 256)      33024       ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 75, 256)      0           ['batch_normalization_90[0][0]', \n",
      "                                                                  'conv1d_100[0][0]']             \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 75, 256)      0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_101 (Conv1D)            (None, 75, 256)      196864      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 75, 256)     1024        ['conv1d_101[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 75, 256)      0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_102 (Conv1D)            (None, 75, 256)      196864      ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 75, 256)     1024        ['conv1d_102[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 75, 256)      0           ['batch_normalization_92[0][0]', \n",
      "                                                                  'activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 75, 256)      0           ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_103 (Conv1D)            (None, 75, 256)      196864      ['activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 75, 256)     1024        ['conv1d_103[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 75, 256)      0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_104 (Conv1D)            (None, 75, 256)      196864      ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 75, 256)     1024        ['conv1d_104[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 75, 256)      0           ['batch_normalization_94[0][0]', \n",
      "                                                                  'activation_92[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 75, 256)      0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 256)         0           ['activation_94[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 12)           3084        ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,512,268\n",
      "Trainable params: 1,506,764\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Add, GlobalAveragePooling1D, Dense\n",
    "\n",
    "def residual_block(input_tensor, filters, kernel_size, strides=1):\n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Downsample the input tensor if strides=2\n",
    "    if strides == 2:\n",
    "        input_tensor = Conv1D(filters, 1, strides=strides, padding='same')(input_tensor)\n",
    "    \n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=(300, 64))\n",
    "\n",
    "# Initial convolution\n",
    "x = Conv1D(64, 7, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Residual blocks\n",
    "x = residual_block(x, 64, 3)\n",
    "x = residual_block(x, 64, 3)\n",
    "x = residual_block(x, 64, 3)\n",
    "\n",
    "x = residual_block(x, 128, 3, strides=2)\n",
    "x = residual_block(x, 128, 3)\n",
    "x = residual_block(x, 128, 3)\n",
    "\n",
    "x = residual_block(x, 256, 3, strides=2)\n",
    "x = residual_block(x, 256, 3)\n",
    "x = residual_block(x, 256, 3)\n",
    "\n",
    "# Global average pooling\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(12, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1af1e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "631/631 [==============================] - 257s 394ms/step - loss: 1.2226 - accuracy: 0.5747 - val_loss: 0.9877 - val_accuracy: 0.6567\n",
      "Epoch 2/50\n",
      "414/631 [==================>...........] - ETA: 6:05 - loss: 0.8003 - accuracy: 0.7260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\keras\\engine\\training.py:1685\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1677\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1678\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1679\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1682\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1683\u001B[0m ):\n\u001B[0;32m   1684\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1685\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1687\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    891\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 894\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    896\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    897\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    923\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    924\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    925\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 926\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    927\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    928\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    929\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    930\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    141\u001B[0m   (concrete_function,\n\u001B[0;32m    142\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1753\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1755\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1756\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1757\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1758\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1759\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1760\u001B[0m     args,\n\u001B[0;32m   1761\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1762\u001B[0m     executing_eagerly)\n\u001B[0;32m   1763\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    380\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 381\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    384\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    387\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    388\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    389\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    390\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    393\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    394\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=20, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_classes = []\n",
    "y_real_classes = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_classes.append(np.argmax(item))\n",
    "\n",
    "for item in y_test:\n",
    "    y_real_classes.append(np.argmax(item))\n",
    "    \n",
    "print(y_pred_classes[0])\n",
    "print(y_real_classes[0])\n",
    "# Assuming your classes are labeled from 0 to 25\n",
    "predicted_class = np.argmax(y_pred[0])\n",
    "probability = y_pred[0][predicted_class]\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Probability:\", probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e58082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_real_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_real_classes, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
